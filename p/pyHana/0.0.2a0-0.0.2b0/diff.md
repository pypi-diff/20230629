# Comparing `tmp/pyHana-0.0.2a0-py3-none-any.whl.zip` & `tmp/pyHana-0.0.2b0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,32 @@
-Zip file size: 22275 bytes, number of entries: 19
--rw-rw-rw-  2.0 fat       87 b- defN 23-Jun-11 03:47 pyHana/__init__.py
+Zip file size: 35101 bytes, number of entries: 30
+-rw-rw-rw-  2.0 fat       85 b- defN 23-Jun-25 16:00 pyHana/__init__.py
 -rw-rw-rw-  2.0 fat       28 b- defN 23-Jun-04 13:58 pyHana/analysis/__init__.py
--rw-rw-rw-  2.0 fat    16582 b- defN 23-Jun-18 12:17 pyHana/analysis/stockEcoIndex.py
+-rw-rw-rw-  2.0 fat    16752 b- defN 23-Jun-28 14:17 pyHana/analysis/stockEcoIndex.py
 -rw-rw-rw-  2.0 fat       48 b- defN 23-Jun-09 22:21 pyHana/common/__init__.py
--rw-rw-rw-  2.0 fat      516 b- defN 23-Jun-15 13:44 pyHana/common/conf.py
--rw-rw-rw-  2.0 fat     1121 b- defN 23-Jun-18 12:45 pyHana/common/dataProc.py
+-rw-rw-rw-  2.0 fat     2827 b- defN 23-Jun-29 12:26 pyHana/common/code.py
+-rw-rw-rw-  2.0 fat      624 b- defN 23-Jun-24 14:46 pyHana/common/conf.py
+-rw-rw-rw-  2.0 fat     1535 b- defN 23-Jun-26 14:01 pyHana/common/dataProc.py
 -rw-rw-rw-  2.0 fat     5047 b- defN 23-Jun-08 04:17 pyHana/common/graph.py
--rw-rw-rw-  2.0 fat      681 b- defN 23-Jun-04 14:07 pyHana/common/urlProc.py
--rw-rw-rw-  2.0 fat       56 b- defN 23-Jun-09 22:22 pyHana/innerIO/__init__.py
+-rw-rw-rw-  2.0 fat      681 b- defN 23-Jun-20 14:05 pyHana/common/urlProc.py
+-rw-rw-rw-  2.0 fat       64 b- defN 23-Jun-29 14:00 pyHana/dataSync/__init__.py
+-rw-rw-rw-  2.0 fat     3541 b- defN 23-Jun-25 14:36 pyHana/dataSync/dartSync.py
+-rw-rw-rw-  2.0 fat    12955 b- defN 23-Jun-28 14:01 pyHana/dataSync/ebestSync.py
+-rw-rw-rw-  2.0 fat     2083 b- defN 23-Jun-25 14:36 pyHana/dataSync/kindSync.py
+-rw-rw-rw-  2.0 fat      348 b- defN 23-Jun-25 14:40 pyHana/dataSync/marketIndexSync.py
+-rw-rw-rw-  2.0 fat       73 b- defN 23-Jun-25 07:13 pyHana/innerIO/__init__.py
+-rw-rw-rw-  2.0 fat     1675 b- defN 23-Jun-25 15:46 pyHana/innerIO/companyInfo.py
 -rw-rw-rw-  2.0 fat     2144 b- defN 23-Jun-18 12:21 pyHana/innerIO/ecoIndex.py
+-rw-rw-rw-  2.0 fat     2208 b- defN 23-Jun-25 14:36 pyHana/innerIO/marketIndex.py
 -rw-rw-rw-  2.0 fat     6324 b- defN 23-Jun-18 12:21 pyHana/innerIO/stockData.py
--rw-rw-rw-  2.0 fat       61 b- defN 23-Jun-09 22:22 pyHana/outerIO/__init__.py
--rw-rw-rw-  2.0 fat    21451 b- defN 23-Jun-07 11:29 pyHana/outerIO/dart.py
--rw-rw-rw-  2.0 fat    14998 b- defN 23-Jun-18 12:21 pyHana/outerIO/ebest.py
+-rw-rw-rw-  2.0 fat     5646 b- defN 23-Jun-29 03:45 pyHana/innerIO/stockInfo.py
+-rw-rw-rw-  2.0 fat       72 b- defN 23-Jun-24 12:59 pyHana/outerIO/__init__.py
+-rw-rw-rw-  2.0 fat     5465 b- defN 23-Jun-25 05:55 pyHana/outerIO/dart.py
+-rw-rw-rw-  2.0 fat    15300 b- defN 23-Jun-28 14:01 pyHana/outerIO/ebest.py
 -rw-rw-rw-  2.0 fat     1840 b- defN 23-Jun-18 12:21 pyHana/outerIO/ecoIndex.py
--rw-rw-rw-  2.0 fat      284 b- defN 23-Jun-18 14:16 pyHana-0.0.2a0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-18 14:16 pyHana-0.0.2a0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        7 b- defN 23-Jun-18 14:16 pyHana-0.0.2a0.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     1516 b- defN 23-Jun-18 14:16 pyHana-0.0.2a0.dist-info/RECORD
-19 files, 72883 bytes uncompressed, 19805 bytes compressed:  72.8%
+-rw-rw-rw-  2.0 fat     6535 b- defN 23-Jun-25 04:27 pyHana/outerIO/kind.py
+-rw-rw-rw-  2.0 fat     1800 b- defN 23-Jun-24 12:01 pyHana/outerIO/marketIndex.py
+-rw-rw-rw-  2.0 fat      704 b- defN 23-Jun-29 14:19 pyHana-0.0.2b0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-29 14:19 pyHana-0.0.2b0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        7 b- defN 23-Jun-29 14:19 pyHana-0.0.2b0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     2440 b- defN 23-Jun-29 14:19 pyHana-0.0.2b0.dist-info/RECORD
+30 files, 98943 bytes uncompressed, 31195 bytes compressed:  68.5%
```

## zipnote {}

```diff
@@ -6,53 +6,86 @@
 
 Filename: pyHana/analysis/stockEcoIndex.py
 Comment: 
 
 Filename: pyHana/common/__init__.py
 Comment: 
 
+Filename: pyHana/common/code.py
+Comment: 
+
 Filename: pyHana/common/conf.py
 Comment: 
 
 Filename: pyHana/common/dataProc.py
 Comment: 
 
 Filename: pyHana/common/graph.py
 Comment: 
 
 Filename: pyHana/common/urlProc.py
 Comment: 
 
+Filename: pyHana/dataSync/__init__.py
+Comment: 
+
+Filename: pyHana/dataSync/dartSync.py
+Comment: 
+
+Filename: pyHana/dataSync/ebestSync.py
+Comment: 
+
+Filename: pyHana/dataSync/kindSync.py
+Comment: 
+
+Filename: pyHana/dataSync/marketIndexSync.py
+Comment: 
+
 Filename: pyHana/innerIO/__init__.py
 Comment: 
 
+Filename: pyHana/innerIO/companyInfo.py
+Comment: 
+
 Filename: pyHana/innerIO/ecoIndex.py
 Comment: 
 
+Filename: pyHana/innerIO/marketIndex.py
+Comment: 
+
 Filename: pyHana/innerIO/stockData.py
 Comment: 
 
+Filename: pyHana/innerIO/stockInfo.py
+Comment: 
+
 Filename: pyHana/outerIO/__init__.py
 Comment: 
 
 Filename: pyHana/outerIO/dart.py
 Comment: 
 
 Filename: pyHana/outerIO/ebest.py
 Comment: 
 
 Filename: pyHana/outerIO/ecoIndex.py
 Comment: 
 
-Filename: pyHana-0.0.2a0.dist-info/METADATA
+Filename: pyHana/outerIO/kind.py
+Comment: 
+
+Filename: pyHana/outerIO/marketIndex.py
+Comment: 
+
+Filename: pyHana-0.0.2b0.dist-info/METADATA
 Comment: 
 
-Filename: pyHana-0.0.2a0.dist-info/WHEEL
+Filename: pyHana-0.0.2b0.dist-info/WHEEL
 Comment: 
 
-Filename: pyHana-0.0.2a0.dist-info/top_level.txt
+Filename: pyHana-0.0.2b0.dist-info/top_level.txt
 Comment: 
 
-Filename: pyHana-0.0.2a0.dist-info/RECORD
+Filename: pyHana-0.0.2b0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pyHana/__init__.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
 ## pyHana 패키지
-__all__ =  ['analysis','common','dataSync','innerIO','outerIO' ]
+__all__ =  ['analysis','common','dataSync','innerIO','outerIO' ]
```

## pyHana/analysis/stockEcoIndex.py

```diff
@@ -2,16 +2,17 @@
 from   scipy    import stats
 import pandas   as pd 
 import os, sys
 import datetime as dt
 
 # here = os.path.dirname(__file__)
 # sys.path.append(os.path.join(here, '..'))
-from  ..innerIO  import ecoIndex       as de
-from  ..innerIO  import stockData      as sd
+from  ..innerIO  import marketIndex    as de
+from  ..innerIO  import stockInfo      as sd
+from  ..common   import code
 
 
 XNOR = lambda x,y: 1 if (x>0 and y>0) or (x<0 and y<0) else 0
 XOR  = lambda x,y: 1 if (x>0 and y<0) or (x<0 and y>0) else 0
 
 
 def _MakeFullDayData(listData, indexGrowthSign='B', consecutiveCntForSignChange=1):
@@ -80,30 +81,30 @@
             listIdx += 1
             
         resData.append([cDate, lastVal, signal])
     
     return resData
 
 
-def _MergeStockIndex(listStock, listEcoIndex, sDate, eDate, advance):
+def _MergeStockIndex(listStock, listMarketIndex, sDate, eDate, advance):
     idxS = 0
     idxE = 0
     
     mergeData = []
     
     # 일별 주가와 일별 경제 지수 merge (선행 advance일수 반영)
-    while idxS < len(listStock) and idxE < len(listEcoIndex):
+    while idxS < len(listStock) and idxE < len(listMarketIndex):
         
-        if listStock[idxS][0] < listEcoIndex[idxE][0]:
+        if listStock[idxS][0] < listMarketIndex[idxE][0]:
             idxS += 1
-        elif listStock[idxS][0] > listEcoIndex[idxE][0]:
+        elif listStock[idxS][0] > listMarketIndex[idxE][0]:
             idxE += 1        
         else:
             if (idxE + advance) >= 0 and sDate <= listStock[idxS][0] and listStock[idxS][0] <= eDate:
-                mergeData.append( listStock[idxS] + listEcoIndex[idxE + advance] )
+                mergeData.append( listStock[idxS] + listMarketIndex[idxE + advance] )
                 
             idxS += 1
             idxE += 1
 
     return mergeData
 
 def _GetDailySimulationData(investAmt, mergeData, feeRatio, taxRatio, priceType, indexNm):    
@@ -137,18 +138,18 @@
         
     return pd.DataFrame(resData, columns=['거래일자', priceType, 'Index기준일자', indexNm, 'Signal',
                                           '보유주수','거래금액', '수수료', '거래세', '현금', '평가금액'])
 
 def GetIndexValueList(indexNm):
     if indexNm not in ('BDI','BCI','BPI','BSI'):
         print(indexNm, flush=True)
-        retVal = sd.ReadOverseasIndexInfo(indexNm)['data']
+        retVal = sd.ReadEbestMarketIndexInfo(indexNm)['data']
         retVal = [[x[0], float(x[1])] for x in retVal]
     else:
-        retVal = de.ReadEcoIndex(indexNm, objTyp='list')['data']
+        retVal = de.ReadMarketIndex(indexNm, objTyp='list')['data']
     
     return retVal
 
 def TradeSimulation(priceType, indexNm, shCodes=[], 
                     sDate='00000101',  eDate='99991231', investAmt=10000000, advance=-1, feeRatio=0.015, taxRatio=0.3, indexGrowthSign='B',
                     consecutiveCntForSignChange=1):
     """
@@ -164,47 +165,48 @@
         분석대상(shCodes)이 단일종목인 경우, 일자별 simulation 내역 return
         복수 종목인 경우 simulation summary 데이터 return
     """
      
     # 1년 365일 모든 일자에 대해 경제지수 데이터 생성 (없는 경우 전일 데이터 값으로 생성)
     # 선행일수 고려 증권거래일자와 매핑을 하기 위한 사전 작업
 
-    # listEcoIndex = _MakeFullDayData( de.ReadEcoIndex(indexNm, objTyp='list')['data'], indexGrowthSign )    
+    # listMarketIndex = _MakeFullDayData( de.ReadMarketIndex(indexNm, objTyp='list')['data'], indexGrowthSign )    
 
     indexValueList = GetIndexValueList(indexNm)
 
-    listEcoIndex = _MakeFullDayData(indexValueList, indexGrowthSign=indexGrowthSign, 
+    listMarketIndex = _MakeFullDayData(indexValueList, indexGrowthSign=indexGrowthSign, 
                                     consecutiveCntForSignChange=consecutiveCntForSignChange )    
 
     if type(shCodes) == str:
         # listStock = sd.ReadStockTrade(shCodes)[['일자', priceType]].values.tolist()
         listStock = sd.ReadStockTrade(shCodes)[['일자', priceType]].astype({priceType:'int64'}).values.tolist()
         
         # 주가정보와 지표정보를 선행 기준에 의해 병합
-        mergeData = _MergeStockIndex(listStock, listEcoIndex, sDate, eDate, advance)
+        mergeData = _MergeStockIndex(listStock, listMarketIndex, sDate, eDate, advance)
 
         # 병합한 데이터로 거래 simulation 수행 
         retVal = _GetDailySimulationData(investAmt, mergeData, feeRatio, taxRatio, priceType, indexNm)
     else:
         resData = []
 
         if type(shCodes) == type(pd.DataFrame([])):
             shCodes = shCodes.values.tolist()  
         
         print(dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'total cnt >> ', len(shCodes))
 
         for i, shCode in enumerate(shCodes):
             
             # shName = dfStock['종목명'].iloc[i]
-            shName = sd.ReadStockItemInfo(shCode)['종목명'][0]
+            # shName = sd.ReadStockItemInfo(shCode)['종목명'][0]
+            shName = code._GetCmpnyName(shCode)
 
             listStock = sd.ReadStockTrade(shCode)[['일자', priceType]].values.tolist()
 
             # 주가정보와 지표정보를 선행 기준에 의해 병합
-            mergeData = _MergeStockIndex(listStock, listEcoIndex, sDate, eDate, advance)
+            mergeData = _MergeStockIndex(listStock, listMarketIndex, sDate, eDate, advance)
 
             # 병합한 데이터로 거래 simulation 수행 
             df = _GetDailySimulationData(investAmt, mergeData, feeRatio, taxRatio, priceType, indexNm)
                      
             if len(df) > 0:
                 idxLast = len(df) - 1
                 resData.append( [ shCode, shName, indexGrowthSign, 
@@ -239,15 +241,15 @@
         상관계수 return
     """
      
     # 1년 365일 모든 일자에 대해 경제지수 데이터 생성 (없는 경우 전일 데이터 값으로 생성)
     # 선행일수 고려 증권거래일자와 매핑을 하기 위한 사전 작업
 
     indexValueList = GetIndexValueList(indexNm)
-    listEcoIndex = _MakeFullDayData(indexValueList)    
+    listMarketIndex = _MakeFullDayData(indexValueList)    
 
     if type(shCodes) == str:
         shCodes = [shCodes]
     elif type(shCodes) == type(pd.DataFrame([])):
         shCodes = shCodes.values.tolist()  
 
     if deltaValInd == 'Y':
@@ -257,20 +259,21 @@
 
     print(dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'total cnt >> ', len(shCodes))
 
     resData = []   
     for i, shCode in enumerate(shCodes):
         
         # shName = dfStock['종목명'].iloc[i]
-        shName = sd.ReadStockItemInfo(shCode)['종목명'][0]
+        # shName = sd.ReadStockItemInfo(shCode)['종목명'][0]
+        shName = code._GetCmpnyName(shCode)
 
         listStock = sd.ReadStockTrade(shCode)[['일자', priceType]].values.tolist()
 
         # 주가정보와 지표정보를 선행 기준에 의해 병합
-        mergeData = _MergeStockIndex(listStock, listEcoIndex, sDate, eDate, advance)
+        mergeData = _MergeStockIndex(listStock, listMarketIndex, sDate, eDate, advance)
 
         # 병합한 데이터로 Correlation Value 계산 
         corrVal = CalcCorrRelation([x[1] for x in mergeData], [x[3] for x in mergeData],
                                     deltaValInd, minimumDataCnt)
         if len(corrVal) > 0:
             resData.append([shCode, shName] + corrVal)
```

## pyHana/common/conf.py

```diff
@@ -2,16 +2,19 @@
 import configparser
 
 # 설정파일 읽기
 configPath = os.environ['PyhanaConfigPath']
 config = configparser.ConfigParser()    
 config.read(configPath+'/config.ini', encoding='utf-8') 
 
+print(configPath+'/config.ini')
+
 ebestId  = config['ebest']['id']
 ebestPwd = config['ebest']['pwd']
 certPwd  = config['ebest']['certpwd']
 xingAPIRes = config['ebest']['xingAPIRes']
 
-basePath = config['path']['base']
-dartPath = config['path']['dart']
-ecoIndexPath = config['path']['ecoIndex']
-stockTradePath = config['path']['stockTrade']
+basePath        = config['path']['base']
+fileInfoPath    = config['path']['fileInfo']
+marketIndexPath = config['path']['marketIndex']
+stockInfoPath   = config['path']['stockInfo']
+companyInfoPath = config['path']['companyInfo']
```

## pyHana/common/dataProc.py

```diff
@@ -1,8 +1,9 @@
 import pickle
+import os
 import gzip
 
 def ReadPickleFile(filePathNm, gzipInd=True):
     try:
         if gzipInd:
             with gzip.open(filePathNm, 'rb') as f:
                 retVal = pickle.load(f)      
@@ -11,24 +12,36 @@
                 retVal = pickle.load(f)      
     except:
         retVal = {}
     
     return retVal
 
 def WritePickleFile(filePathNm, currData, gzipInd=True):
+    dirName = os.path.dirname(filePathNm)
+    if not os.path.isdir(dirName):
+        os.makedirs(dirName, exist_ok=True)
+
     if gzipInd:
         with gzip.open(filePathNm, 'wb') as f:
             pickle.dump(currData, f)       
     else:
         with open(filePathNm, 'wb') as f:
             pickle.dump(currData, f)           
 
-def MergeData(currData, newData):
+def _MergeData(currData, newData, sortCols=1):
+    # sortCols 병합 시 중복 판단 기준 컬럼 수(앞에서부터)
     # 기존 데이터의 우선순위는 2, 신규 데이터는 우선순위 1로 병합 후 sort
-    totList = [[x[0], 2] + x[1:] for x in currData ] \
-            + [[x[0], 1] + x[1:] for x in newData ]
+    totList = [ x[0:sortCols] + [2] + x[sortCols:] for x in currData ] \
+            + [ x[0:sortCols] + [1] + x[sortCols:] for x in newData ]
+    
+    # print(currData)
+    # print(newData)
+    # print(totList)
+    
     totList.sort()
 
     # 중복데이터 제거 및 임시 우선순위 삭제
-    noDupList = [ [data[0]] + data[2:] for idx, data in enumerate(totList) if idx == 0 or data[0] > totList[idx-1][0] ] 
+    noDupList = [ data[0:sortCols] + data[(sortCols+1):] 
+                 for idx, data in enumerate(totList) if idx == 0 or data[0:sortCols] > totList[idx-1][0:sortCols] 
+                ] 
 
     return noDupList
```

## pyHana/innerIO/__init__.py

```diff
@@ -1,2 +1,2 @@
 ## pyHana 패키지
-__all__ =  ['ecoIndex','stockData']
+__all__ =  ['companyInfo','marketIndex','stockInfo']
```

## pyHana/outerIO/__init__.py

```diff
@@ -1,2 +1,2 @@
 ## pyHana 패키지
-__all__ =  ['dart', 'ebest', 'ecoIndex']
+__all__ =  ['dart', 'ebest', 'kind', 'marketIndex']
```

## pyHana/outerIO/dart.py

```diff
@@ -1,293 +1,138 @@
-import pandas as pd
-import pickle
-import math
-import gzip
-
-# 결산기준일 변환 함수 SET_DT(2023,2) => 2023-06-30
-SET_DT = lambda year, quarter : str(year)+'-'+"%02d"%(quarter * 3)+'-'+'%2d'%(31 if quarter in(1,4) else 30)
-
-FILE_COLUMNS = {
-            "02_손익계산서" :    {
-                "1분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 1분기 3개월","당기 1분기 누적",
-                                "전기 1분기 3개월","전기 1분기 누적","전기","전전기"],
-                "반기보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 반기 3개월", "당기 반기 누적",
-                                "전기 반기 3개월","전기 반기 누적","전기","전전기"],
-                "3분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 3분기 3개월","당기 3분기 누적",
-                                "전기 3분기 3개월","전기 3분기 누적","전기","전전기"],
-                "사업보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기","전기","전전기"]
-            },
-            "02_손익계산서_연결" :    {
-                "1분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 1분기 3개월","당기 1분기 누적",
-                                "전기 1분기 3개월","전기 1분기 누적","전기","전전기"],
-                "반기보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 반기 3개월", "당기 반기 누적",
-                                "전기 반기 3개월","전기 반기 누적","전기","전전기"],
-                "3분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 3분기 3개월","당기 3분기 누적",
-                                "전기 3분기 3개월","전기 3분기 누적","전기","전전기"],
-                "사업보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기","전기","전전기"]
-            },    
-            "03_포괄손익계산서" : {
-                "1분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 1분기 3개월","당기 1분기 누적",
-                                "전기 1분기 3개월","전기 1분기 누적","전기","전전기"],
-                "반기보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 반기 3개월", "당기 반기 누적",
-                                "전기 반기 3개월","전기 반기 누적","전기","전전기"],
-                "3분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 3분기 3개월","당기 3분기 누적",
-                                "전기 3분기 3개월","전기 3분기 누적","전기","전전기"],
-                "사업보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기","전기","전전기"]
-
-            },    
-            "03_포괄손익계산서_연결" : {
-                "1분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 1분기 3개월","당기 1분기 누적",
-                                "전기 1분기 3개월","전기 1분기 누적","전기","전전기"],
-                "반기보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 반기 3개월", "당기 반기 누적",
-                                "전기 반기 3개월","전기 반기 누적","전기","전전기"],
-                "3분기보고서" : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기 3분기 3개월","당기 3분기 누적",
-                                "전기 3분기 3개월","전기 3분기 누적","전기","전전기"],
-                "사업보고서"  : ["재무제표종류","종목코드","회사명","시장구분","업종","업종명","결산월","결산기준일","보고서종류","통화","항목코드","항목명","당기","전기","전전기"]
-
-            }
-        }
-
-class DART:
-    def __init__(self, file_path):
-        """
-        Args:
-            (str) file_path : DART 일괄다운로드 파일 위치        
-        """ 
-        if file_path.endswith('/'):
-            self.file_path = file_path
-        else:
-            self.file_path = file_path + '/'
-        
-        self.dartInfoDict = self._ReadFinalcialInfo()
-        
+from   bs4      import BeautifulSoup as bs
+import time  
+import re
+from ..common  import urlProc
+
+def GetCmpnyAcntInfo(year, quarter, selectToc=5, currentPageSize = 100):
+    # selectToc : 0 (연결재무제표), 5(재무제표)
+    # reportCode : 11013(1분기), 11012(반기), 11014(3분기), 11011(사업보고서)
+    if   quarter == 1:  reportCode = ['11013','1분기']
+    elif quarter == 2:  reportCode = ['11012','반기']
+    elif quarter == 3:  reportCode = ['11014','3분기']
+    elif quarter == 4:  reportCode = ['11011','사업']
+    else:               reportCode = ['','']    
+
+    columns = ['자산총계','부채총계','자본총계','유동자산','유동부채','자본금','비유동자산','비유동부채','이익잉여금',
+               '매출액','당기순이익','영업이익','세전이익']
     
-    def _Pandas_ReadCsv_DartFile(self, year, quarter, reportKnd):
-        """DART에서 제공하는 재무정보 일괄 다운로드 파일 읽기
+    resData = []
 
-        Args:
-            (int) year               : 공시 년도
-            (int) quarter            : 공시 분기 (1, 2, 3, 4)
-            (str) reportKnd          : 재무정보 종류 ("02_손익계산서", "03_포괄손익계산서" )
-        """        
-                
-        periodKnd = list(FILE_COLUMNS[reportKnd])[quarter-1] # quarter : 1(1분기보고서), 2(반기보고서), 3(3분기보고서), 4(사업보고서)
-        fileNm = self.file_path + "%s_"%(year) + periodKnd + "_" + reportKnd + '.txt'
-        print(fileNm, flush=True)
+    urlTmp = "https://opendart.fss.or.kr/disclosureinfo/fnltt/cmpnyacnt/list.do?sortStdr=&sortOrdr=asc"
+    urlTmp += "&textCrpCik=&textCrpNm=&typesOfBusiness=&corporationType=&accountGubunAll=on"
+    urlTmp += "&accountGubun=1" # 유동자산
+    urlTmp += "&accountGubun=2" # 비유동자산
+    urlTmp += "&accountGubun=3" # 자산총계
+    urlTmp += "&accountGubun=4" # 유동부채
+    urlTmp += "&accountGubun=5" # 비유동부채
+    urlTmp += "&accountGubun=6" # 부채총계
+    urlTmp += "&accountGubun=7" # 자본금
+    urlTmp += "&accountGubun=8" # 이익잉여금
+    urlTmp += "&accountGubun=9" # 자본총계
+    urlTmp += "&accountGubun=10" # 매출액
+    urlTmp += "&accountGubun=11" # 영업이익
+    urlTmp += "&accountGubun=12" # 법인세차감전순이익
+    urlTmp += "&accountGubun=13" # 당기순이익  
+    urlTmp += "&recordCountPerPage={}&selectYear={}&reportCode={}&selectToc={}".format(currentPageSize, year, reportCode[0], selectToc)
+    urlTmp += "&pageIndex={}"
+               
+    skipCnt = 0
+    pgNum = 1
+    while True:                
+        # res = req.get(url)
+        url = urlTmp.format(pgNum)
+
+        res = urlProc.requests_url_call(url)
+
+        soup = bs(res.text, "html.parser")
+
+        trs = soup.tbody.select("tr")
+        for tr in trs:    
+            tds = tr.select("td")
+
+            tdVal = []
+            for idx, td in enumerate(tds):
+                if idx == 0:
+                    
+                    title = td.select_one("span.com").text
+                    fiscalMon = td.p.text.strip() 
+                    
+                    if fiscalMon == '(-)':
+                        # print('skip >> ', title)
+                        skipCnt += 1
+                        break
+                    
+                    fiscalMon = fiscalMon.split(",")[1].replace("결산)","")
+                    if fiscalMon == '03월':
+                        quarterNew = (quarter + 1) if quarter <=3 else 1
+                    else:
+                        quarterNew = quarter
+                    # 종목명, 결산월, 기준년도, 기준분기, 보고서종류
+                    tdVal = [title, fiscalMon, year, quarterNew, reportCode[1]]
+                else:        
+                    val = re.sub(r"[^0-9]", "", td.text.strip())
+                    if len(val) > 0:
+                        val = int(val)
+                    tdVal.append(val)
+
+            if len(tdVal) > 0:
+                resData.append(tdVal)        
+
+        x=soup.select_one("div.page_info").text.replace(",","")
+        curNum = int(x.split("/")[0][1:])
+        totNum = int(x.split("/")[1].split("]")[0])
         
-        try:    
-            dfData = pd.read_csv(fileNm, sep='\t', engine='python', encoding='CP949', usecols=FILE_COLUMNS[reportKnd][periodKnd])
-        except:
-            dfData = pd.read_csv(fileNm, sep='\t', engine='python', encoding='utf-8', usecols=FILE_COLUMNS[reportKnd][periodKnd])
-            
-        return dfData
+        if curNum >= totNum:
+            break
 
-    def GetFinancialDataFromDartFile(self, year, quarter):
-        """DART에서 제공하는 재무정보 일괄 다운로드 파일("02_손익계산서", "03_포괄손익계산서" ) 내용 중
-           매출액, 영업이익, 당기순이익, 총포괄손익 정보 추출하여 DataFrame 형태로 반환
-        
-        Args:
-            (int) year               : 공시 년도
-            (int) quarter            : 공시 분기 (1, 2, 3, 4)
-        반환항목:
-            종목코드, 회사명, 매출액, 영업이익, 법인세전이익, 법인세, 당기순이익,
-            총포괄손익, 총포괄(손익)_소유주(지분),'총포괄(손익)_비지배(지분)'
-        """             
-        if quarter == 1:        valueColumn = '당기 1분기 3개월'
-        elif quarter == 2:      valueColumn = '당기 반기 3개월'
-        elif quarter == 3:      valueColumn = '당기 3분기 3개월'
-        elif quarter == 4:      valueColumn = '당기'
-
-        dfSum = pd.DataFrame({})
-
-        for reportKnd in ["03_포괄손익계산서_연결", "02_손익계산서_연결", "03_포괄손익계산서", "02_손익계산서"]:
-            # (연결)손익계산서에 정보가 없는 경우를 대비해 (삼성전자 2019년 1,2분기 매출액 등)
-            # 낮은 우선순위로 (일반)손익계산서 반영
-            if reportKnd in ( "02_손익계산서", "03_포괄손익계산서" ):
-                addPriority = 10
-            else:
-                addPriority = 0
-
-            dfData = self._Pandas_ReadCsv_DartFile(year, quarter, reportKnd)
-
-            # 데이터 클린징
-            dfData = dfData.dropna(subset=[valueColumn], how='any', axis=0)
-            dfData['종목코드'] = dfData['종목코드'].str.replace(']','').str.replace('[','')            
-            dfData['항목명'] = dfData['항목명'].str.strip().str.replace('.','').str.replace(' ','').str.replace('I','')
-
-            # 보고서별 항목명이 달라서 value로 통일
-            dfData['value']  = dfData[valueColumn]
-
-            # 각 항목별 데이터가 일관되게 작성되어 있지 않아 손익계산서와 포괄손익 계산서를 merge하여 구함
-            # 우선순위 : 항목코드 정확하게 매칭(1순위), 검증결과 해당 항목으로 추정되는 항목명(2순위)            
-            extCond = [ 
-                 {"통합계정명" : "매출액",       "우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_Revenue','ifrs_Revenue'] ] } 
-                ,{"통합계정명" : "매출액",       "우선순위" : 2, "조건" : [ "항목명"  ,  ['매출', '영업수익', '매출액', '영업수익(매출액)','영업수익'] ] }
-                ,{"통합계정명" : "영업이익",     "우선순위" : 1, "조건" : [ "항목명"  ,  ['영업이익'] ] }
-                ,{"통합계정명" : "영업이익",     "우선순위" : 2, "조건" : [ "항목코드",  ['dart_OperatingIncomeLoss'] ] }
-                ,{"통합계정명" : "당기순이익",   "우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_ProfitLoss','ifrs_ProfitLoss'] ] }
-                ,{"통합계정명" : "당기순이익",   "우선순위" : 2, "조건" : [ "항목명",    ['당기순이익', '연결당기순이익', '연결분기순이익', '연결분기순이익(손실)', '분기순손익', '분기순이익'] ] }
-                ,{"통합계정명" : "당기순이익",   "우선순위" : 3, "조건" : [ "항목명end", '분기순이익(손실)' ] }  # endswith는 배열처리 
-                ,{"통합계정명" : "법인세전이익", "우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_ProfitLossBeforeTax','ifrs_ProfitLossBeforeTax'] ] } 
-                ,{"통합계정명" : "법인세",       "우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_IncomeTaxExpenseContinuingOperations','ifrs_IncomeTaxExpenseContinuingOperations'] ] }                                                                                        
-                ,{"통합계정명" : "총포괄손익",   "우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_ComprehensiveIncome','ifrs_ComprehensiveIncome'] ] }
-                ,{"통합계정명" : "총포괄손익",   "우선순위" : 2, "조건" : [ "항목명",    ['당기총포괄손익', '당기총포괄이익(손실)', '분기연결총포괄이익(손실)', '분기총포괄손익', '분기총포괄이익(손실)',
-                                                                                        '연결포괄이익', '연결총포괄손익', '연결총포괄이익(손실)', '총포괄이익(손실)'] ] }
-                ,{"통합계정명" : "총포괄_소유주","우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_ComprehensiveIncomeAttributableToOwnersOfParent','ifrs_ComprehensiveIncomeAttributableToOwnersOfParent'] ] }                                                                                         
-                ,{"통합계정명" : "총포괄_소유주","우선순위" : 2, "조건" : [ "항목명",    ['지배지분총포괄이익'] ] }
-                ,{"통합계정명" : "총포괄_비지배","우선순위" : 1, "조건" : [ "항목코드",  ['ifrs-full_ComprehensiveIncomeAttributableToNoncontrollingInterests','ifrs_ComprehensiveIncomeAttributableToNoncontrollingInterests'] ] }                                                                                         
-                ,{"통합계정명" : "총포괄_비지배","우선순위" : 2, "조건" : [ "항목명",    ['비지배지분총포괄이익'] ] }        
-            ]    
-            for idx in range(0, len(extCond)): 
-                if extCond[idx]["조건"][0] == "항목명end":
-                    cond = ( dfData["항목명"].str.endswith(extCond[idx]["조건"][1]) )
-                else:
-                    cond = ( dfData[extCond[idx]["조건"][0]].isin(extCond[idx]["조건"][1]) )
+        pgNum += 1
 
-                # 3월 결산 기준일 회사 제외 (사업보고서에 전년 4월 ~ 당해 3월 데이터 반영)
-                cond = cond & ( dfData["결산기준일"] == SET_DT(year, quarter) )
-                
+        time.sleep(0.1)
+    
+    totRecCnt = soup.select_one("div.page_info").text.replace(" ","").split("총")[1].replace("건]","")
+    print('\r', year, reportCode[1], selectToc, ' >> 대상:', totRecCnt, '제외:', skipCnt, '', len(resData), ' '*40)
 
-                dfTemp = dfData[cond] [['종목코드','회사명', '결산기준일', 'value']]
-                dfTemp['통합계정명'] = extCond[idx]["통합계정명"]
-                dfTemp['우선순위']   = extCond[idx]["우선순위"] + addPriority
-                                
-                dfSum = pd.concat([dfSum, dfTemp])    
-
-        dfSum['value'] = dfSum['value'].str.replace(',','').astype(dtype='int64')
-        dfSum = dfSum.sort_values('우선순위').groupby(['종목코드','회사명','결산기준일','통합계정명']).first().reset_index()
-        dfRes = pd.pivot_table(dfSum, values='value', index=['종목코드','회사명','결산기준일'], columns=['통합계정명'], aggfunc='sum'
-                              ).reset_index()[['종목코드','회사명','결산기준일','매출액','영업이익','당기순이익','법인세전이익','법인세',
-                                               '총포괄손익','총포괄_소유주','총포괄_비지배']]
-        
-        # dataframe을 dictionary로 변환, 저장 후 반환
-        self._MergeIntoFinincialInfo(dfRes)
+    return resData, ['종목명', '결산월', '기준년도', '기준분기', '보고서종류'] + columns
 
 
-    def _MergeIntoFinincialInfo(self, data):
-        """DART에서 제공하는 재무정보 일괄 다운로드 파일 읽어, 주요 정보 데이터 추출 후 (GetFinancialDataFromDartFile 모듈)
-           기존 저장된 dictionary 데이터에 merge 수행
-           최종 결과는 pickle에 저장하고, 
-           Class변수 self.dartInfoDict에 저장
-
-        Args:
-            (dataframe) data : DART에서 제공하는 재무정보 일괄 다운로드 파일 읽어, 주요 정보 데이터 추출 후 dataframe 형태로 저장
-        """                
-            
-        dartInfoDict = self.dartInfoDict
+def GetCmpnyList():
+    columns = ['회사명','종목코드']
+    
+    resData = []
 
-        for i in range(0, len(data)):
-            shCode = data.iloc[i]["종목코드"]
-            setDt = data.iloc[i]["결산기준일"]
-
-            if not dartInfoDict.get(shCode):
-                dartInfoDict[shCode] = {}
-                dartInfoDict[shCode]['회사명'] = data.iloc[i]["회사명"]
-
-            if not dartInfoDict[shCode].get("결산기준일"):
-                dartInfoDict[shCode]["결산기준일"] = {}
-
-            dartInfoDict[shCode]["결산기준일"][setDt] = {}
-
-            # 1. 매출액
-            if not math.isnan(data.iloc[i]['매출액']):
-                dartInfoDict[shCode]["결산기준일"][setDt]["매출액"] = data.iloc[i]['매출액']
-            # 2. 영업이익    
-            if not math.isnan(data.iloc[i]['영업이익']):
-                dartInfoDict[shCode]["결산기준일"][setDt]["영업이익"] = data.iloc[i]['영업이익']
-            # 3. 당기순이익    
-            if not math.isnan(data.iloc[i]['당기순이익']):
-                dartInfoDict[shCode]["결산기준일"][setDt]["당기순이익"] = data.iloc[i]['당기순이익']
-            # 당기순이익 제출하지 않은 경우 법인세전이익과 법인세로 계산   
-            elif not math.isnan(data.iloc[i]['법인세전이익']):
-                profitLoss = data.iloc[i]['법인세전이익']
-                if not math.isnan(data.iloc[i]['법인세']):
-                    profitLoss -= data.iloc[i]['법인세']
-                dartInfoDict[shCode]["결산기준일"][setDt]["당기순이익"] = profitLoss
-            # 4. 총포괄손익    
-            if not math.isnan(data.iloc[i]['총포괄손익']):
-                dartInfoDict[shCode]["결산기준일"][setDt]["총포괄손익"] = data.iloc[i]['총포괄손익']
-            # 총포괄손익 제출하지 않은 경우 총포괄_소유주지분과 총포괄_비지배지분으로 계산   
-            elif not math.isnan(data.iloc[i]['총포괄_소유주']):
-                comprehensiveIncome = data.iloc[i]['총포괄_소유주']
-                if not math.isnan(data.iloc[i]['총포괄_비지배']):
-                    comprehensiveIncome += data.iloc[i]['총포괄_비지배']
-                dartInfoDict[shCode]["결산기준일"][setDt]["총포괄손익"] = comprehensiveIncome    
-
-        # 최종 결과 pickle 파일에 저장
-        self._WriteFinalcialInfo(dartInfoDict)
-
-        # 
-        self.dartInfoDict = dartInfoDict
-
-    def _ReadFinalcialInfo(self):
-        # load            
-        try:
-            with gzip.open(self.file_path + 'dart_financial_info.pickle', 'rb') as f:
-                data = pickle.load(f)
-        except:
-            print('pickle file load error >> ', self.file_path + 'dart_financial_info.pickle')
-            data = {}
-                
-        return data
+    urlTmp = "https://dart.fss.or.kr/dsae001/search.ax?startDate=&endDate=&maxResults=&maxLinks=&autoSearch=true&businessCode=all"
+    urlTmp += "&sort=&series=&selectKey=&searchIndex=&textCrpCik=&bsnRgsNo=&bsnRgsNo_1=&bsnRgsNo_2=&bsnRgsNo_3=&crpRgsNo=&textCrpNm="
+    urlTmp += "&corporationType={}&currentPage={}"
 
-    def _WriteFinalcialInfo(self, data):
-        # save
-        # with gzip.open(self.file_path + 'dart_financial_info.pickle', 'wb') as f:
-        with gzip.open(self.file_path + 'dart_financial_info.pickle', 'wb') as f:
-            pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)
-
-    def GetCompanyFinInfoDataFrame(self, shCode, unit="억"):
-
-        df = pd.DataFrame([])
-        for idx, acct in enumerate(['매출액','영업이익','당기순이익','총포괄손익']):
-            data = self.GetCompanyAcctFinInfo(shCode, acct, unit="억")
-            data = list(zip(*data))
-            if idx ==0 :
-                df['결산기준일'] = pd.DataFrame(data[0])
+    for corpType in ('P','A'):
+        pgNum = 1
+        while True:                
+            url = urlTmp.format(corpType, pgNum)
 
-            df[acct] = pd.DataFrame(data[1])
-        
-        return df
-           
+            res = urlProc.requests_url_call(url)
 
-    def GetCompanyAcctFinInfo(self, shCode, acct, unit="억"):
-        acct_list = ['매출액','영업이익','당기순이익','총포괄손익']
-        unit_list = {'천' : 1000, '만' : 10000, '백만' : 1000000, '천만' : 10000000, '억' : 100000000, '십억' : 1000000000, '조' : 1000000000000 }
-        data = []
-        
-        if acct not in acct_list:
-            print('유효하지 않은 계정과목 > ', acct)
-            print('선택가능한 계정과목 > ', acct_list)
-        elif not unit_list.get(unit):
-            print('유효하지 않은 금액단위 > ', unit)
-            print('선택가능한 금액단위 > ', unit_list.keys())        
-        elif self.dartInfoDict.get(shCode):
-            if self.dartInfoDict[shCode].get('결산기준일'):
-                for ymd in sorted(self.dartInfoDict[shCode]['결산기준일'].keys()):
-                    data.append([ymd, self.dartInfoDict[shCode]['결산기준일'][ymd][acct], unit])
+            soup = bs(res.text, "html.parser")
+
+            trs = soup.tbody.select("tr")
+            
+            for tr in trs:    
+                title = tr.td.a.text.strip()
+                shCode = tr.td.next_sibling.next_sibling.text
                 
-        # 사업보고서(4분기)에는 1년 합계 데이터가 있어, 이전 3개 분기의 데이터 필요
-        # 결산기준일 기준으로 정렬하여 추출한 결과값에 대해, 1분기부터 시작하는지, 중간에 누락된 분기는 없는지 확인하여
-        # 누락 발견 시 오류메시지 출력하고 null값 반환
-        if len(data) > 0:
-            for i in range(0, len(data)):
-                if i == 0:
-                    year = int(data[i][0][0:4])
-                    
-                if  (year + int(i / 4)) != int(data[i][0][0:4]) or \
-                    (i % 4) == 0 and data[i][0][5:10] != '03-31' or \
-                    (i % 4) == 1 and data[i][0][5:10] != '06-30' or \
-                    (i % 4) == 2 and data[i][0][5:10] != '09-30' or \
-                    (i % 4) == 3 and data[i][0][5:10] != '12-31':
-                        
-                    print('누락된 분기보고서 오류 > ', i + 1, "번째 데이터")
-                    print(data)
-                    date = []
-                    break
-                    
-                if (i % 4) == 3:   # 사업보고서(년 누적)인 경우 이전 3분기 값 차감 보정
-                    data[i][1] = data[i][1] - data[i-1][1] - data[i-2][1] - data[i-3][1]  
-                    
-            for i in range(0, len(data)):
-                data[i][1] = int(round(data[i][1] / unit_list[unit], 0))
-        return data            
+                resData.append([title, shCode])
+
+            x=soup.select_one("div.pageInfo").text.replace(",","")
+            curNum = int(x.split("/")[0][1:])
+            totNum = int(x.split("/")[1].split("]")[0])
+
+            if curNum >= totNum:
+                break
+
+            pgNum += 1
+
+            time.sleep(0.1)
+
+        totRecCnt = soup.select_one("div.pageInfo").text.replace(" ","").split("총")[1].replace("건]","")
+        print('\ncorporationType(', corpType, ') : ', totRecCnt, '건 추출')
+
+    return resData, columns
+
```

## pyHana/outerIO/ebest.py

```diff
@@ -132,15 +132,20 @@
             print(account)
 
     def CommDisConnect(self):
         if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
 
         self.instXASession.DisconnectServer()
         XAEventHandler.login_state = 0
-        
+
+    def _GetDataFrameKor(self, instXAQuery, blockNm):
+        if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
+        # print(instXAQuery[blockNm]['kor'])
+        return pd.DataFrame(instXAQuery[blockNm]['data'], columns=instXAQuery[blockNm]['kor'])
+
 
     def GetBlockData(self, *args, **kwargs):
         if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
         
         trCode = args[0]        
         inBlockNm = args[1] 
         field_list = args[2] 
@@ -320,39 +325,39 @@
                     for j in range(len(returnData[trBlockNm]['eng'])):
                         fieldData.append(instData.GetFieldData(trBlockNm, returnData[trBlockNm]['eng'][j], i))
 
                     returnData[trBlockNm]['data'].append(fieldData)
 
         return returnData    
 
-    def GetListData(self, instXAQuery, blockNm):
-        if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
-        return instXAQuery[blockNm]['data']
-
-    def GetDataFrameKor(self, instXAQuery, blockNm):
-        if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
-        return pd.DataFrame(instXAQuery[blockNm]['data'], columns=instXAQuery[blockNm]['kor'])
-
-    def GetDataFrameEng(self, instXAQuery, blockNm):
-        if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
-        return pd.DataFrame(instXAQuery[blockNm]['data'], columns=instXAQuery[blockNm]['eng'])
+    # def GetListData(self, instXAQuery, blockNm):
+    #     if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
+    #     return instXAQuery[blockNm]['data']
+
+    # def _GetDataFrameKor(self, instXAQuery, blockNm):
+    #     if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
+    #     return pd.DataFrame(instXAQuery[blockNm]['data'], columns=instXAQuery[blockNm]['kor'])
+
+    # def GetDataFrameEng(self, instXAQuery, blockNm):
+    #     if self.debug: print(dt.datetime.now(), ' > ',  callername(), ' > ', funcname())
+    #     return pd.DataFrame(instXAQuery[blockNm]['data'], columns=instXAQuery[blockNm]['eng'])
     
     def GetStockItemList(self, gubun):
         """
         gubun : '0'(전체) 1'(코스피) '2'(코스닥)             
         """
         dfStock = pd.DataFrame([])  
 
         if gubun in ('1','0'):
             instXAQuery = self.GetTrData('t9945', gubun = '1')
-            dfStock = pd.concat([dfStock, self.GetDataFrameKor(instXAQuery, 't9945OutBlock')], ignore_index=True)
+            dfStock = pd.concat([dfStock, self._GetDataFrameKor(instXAQuery, 't9945OutBlock')], ignore_index=True)
 
         if gubun in ('2','0'):
             instXAQuery = self.GetTrData('t9945', gubun = '2')
-            dfStock = pd.concat([dfStock, self.GetDataFrameKor(instXAQuery, 't9945OutBlock')], ignore_index=True)
+            dfStock = pd.concat([dfStock, self._GetDataFrameKor(instXAQuery, 't9945OutBlock')], ignore_index=True)
 
         dfStock.rename(columns={'단축코드':'종목코드'}, inplace=True)
 
         return  dfStock
 
 
 if __name__ == "__main__":
```

## Comparing `pyHana-0.0.2a0.dist-info/RECORD` & `pyHana-0.0.2b0.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,30 @@
-pyHana/__init__.py,sha256=w9kEe6Nl7_kCDmotLvoH_zr8c7kTTWp9NJbG7b3_OHQ,87
+pyHana/__init__.py,sha256=FKE2JGLKC7jClgKEI0Rmhb_SDPVKK4OwquO5ghyH8yQ,85
 pyHana/analysis/__init__.py,sha256=6AOF6GO_kEJVJTmBcIBqQhpmCH1GtM_NyE1iK9hVOdM,28
-pyHana/analysis/stockEcoIndex.py,sha256=shpoheRwu3Rl7QbY09EJiHHAO02YUIG3-OlUJiUR0gA,16582
+pyHana/analysis/stockEcoIndex.py,sha256=nPPsU6KSwvV-85yOVnSuUum5hfSOHQ1VotWgm-fH8rw,16752
 pyHana/common/__init__.py,sha256=2ggGt-lNxJN960U-VCJX6aEBFVVYd1QZIHtwFXsqBMY,48
-pyHana/common/conf.py,sha256=7YQwr1JudSK0arxiYD8_6-BnKGgAYlOJ22oheJszcGA,516
-pyHana/common/dataProc.py,sha256=UypO8TW2HV02DDmRFdWxurLQwp8VxjgZJlKJRhaX9bg,1121
+pyHana/common/code.py,sha256=7AAiRfZnCSyZ-HW9vl1lpg4Y5iLeelyDhU4S3jhAimE,2827
+pyHana/common/conf.py,sha256=gZXVogXNfdox0Db6iWfLMdgFT1Z-Y3wocmkMzPARmw0,624
+pyHana/common/dataProc.py,sha256=4wlWWcjqKPuXznCIOpMSXKtlvkfm008PFLoVzB7Px20,1535
 pyHana/common/graph.py,sha256=sK6PhesWu_dl03_3RbbuBMvGCGIj2peHKJ_d0fLo91Q,5047
 pyHana/common/urlProc.py,sha256=fW9q14hugz-htEnSoCD53jGv_lWOwWf5kmTAbd_HvLs,681
-pyHana/innerIO/__init__.py,sha256=_HQnYZsDbczSz6jHKdVMcRnMo6X_rcC55k16fAMEJDs,56
+pyHana/dataSync/__init__.py,sha256=146c1GXBxtTeRhnSeCKDOkQ9VwHET_LmM9mKa7MMQMg,64
+pyHana/dataSync/dartSync.py,sha256=EDXw60B_ePGHE-wLlEMg6F9kd37e6HCRc17_IKz12qM,3541
+pyHana/dataSync/ebestSync.py,sha256=p6aCCL1BIpjfPzc4u0lshrd2k9_Wfm08AHbgRtu-Y2k,12955
+pyHana/dataSync/kindSync.py,sha256=5dzaq3RGIVRa6qwkjPPG6v9T1VN4zJCiRMUH8eGqiM8,2083
+pyHana/dataSync/marketIndexSync.py,sha256=49d8lIzmwfadftGM0JvSuJSvu3sDlopXVd0FdfnjlzM,348
+pyHana/innerIO/__init__.py,sha256=_-sW3TqzJuPThVJzoIZZqw3g91-1vCC7jaPS-Sxi184,73
+pyHana/innerIO/companyInfo.py,sha256=Daey3oc2xHM4R0FQh6EpPJ3KqeN4MjsevkO47PQ4ybA,1675
 pyHana/innerIO/ecoIndex.py,sha256=Whf5GEinjaxQSKEHFgiSIaRjIBO9JsC4oTkf5Cppk2I,2144
+pyHana/innerIO/marketIndex.py,sha256=aNGpKmOI7z4vmdtkCa3FcvAYIS9zjYddFrWRdRxIJXs,2208
 pyHana/innerIO/stockData.py,sha256=_Klb7YgfSjwMiKAxHKKqFipUkrCXK1l8HHzfJZF3408,6324
-pyHana/outerIO/__init__.py,sha256=JhxO_Qf0Mlls-Mpw8lZFO-Sf_C09r4Wx4wITxLTi4w0,61
-pyHana/outerIO/dart.py,sha256=d2NXmU6A7MpBEeUv4AdlEKIyTgO7hUGmSdVmp1X627w,21451
-pyHana/outerIO/ebest.py,sha256=dOxOcPgD6Jg_qes9aB1djOme6CsiSqFKpJLX966jneg,14998
+pyHana/innerIO/stockInfo.py,sha256=XZOVfNjd6GwbYuxgLx4oUj5pyABOm9kOYjsvse3GFfg,5646
+pyHana/outerIO/__init__.py,sha256=4ov-xPtJCVADhp1TQ39PBaHJ_Md213hsMzRnGG5qWmE,72
+pyHana/outerIO/dart.py,sha256=MaIz73wzOp8oVSI-OQPKVSOuVBV0advwB6ZJDrbBE8w,5465
+pyHana/outerIO/ebest.py,sha256=RfxR_BwK7RBuHgIsc7_tp_Vi2eLd3OIXh-DpWdUCGEA,15300
 pyHana/outerIO/ecoIndex.py,sha256=Lbu9VrbWYy2Yo57iisfTi6dJlHUkbH1tDcBGeE5xC-c,1840
-pyHana-0.0.2a0.dist-info/METADATA,sha256=VDVRyPKjpBdNkdJXReVgS1PsneiCjmbnz0kQnnxFvoY,284
-pyHana-0.0.2a0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-pyHana-0.0.2a0.dist-info/top_level.txt,sha256=HB0jmziPuwk5hJlWnvEbaS8QkKv84NPwX8F6le7Tm1Y,7
-pyHana-0.0.2a0.dist-info/RECORD,,
+pyHana/outerIO/kind.py,sha256=ZunqvWQpG0s1nTv8QpdoXm1GKyh5VekIoVZVMcJUXsc,6535
+pyHana/outerIO/marketIndex.py,sha256=i6AUpzo8kuSM1TDogLV5uqv877DEVa00PtT6uCHUlaY,1800
+pyHana-0.0.2b0.dist-info/METADATA,sha256=gvIL5KulmYYvEPvtTqlB78wCAt_SgSvBje3kcYHR2ZU,704
+pyHana-0.0.2b0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+pyHana-0.0.2b0.dist-info/top_level.txt,sha256=HB0jmziPuwk5hJlWnvEbaS8QkKv84NPwX8F6le7Tm1Y,7
+pyHana-0.0.2b0.dist-info/RECORD,,
```

